{"version":3,"file":"js/app.19a93474.js","mappings":"kEAAIA,EAAS,WAAa,IAAIC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,QAAQ,CAACA,EAAG,YAAY,CAACE,MAAM,CAAC,IAAM,GAAG,MAAQ,GAAG,OAAS,IAAI,KAAO,GAAG,MAAQ,WAAWC,YAAYP,EAAIQ,GAAG,CAAC,CAACC,IAAI,MAAMC,GAAG,SAASC,GAC5O,IAAIC,EAAQD,EAAIC,MAChB,MAAO,CAACR,EAAG,QAAQJ,EAAIa,GAAG,GAAG,QAAQD,GAAM,OAAW,CAACH,IAAI,YAAYC,GAAG,WAAW,MAAO,CAACN,EAAG,SAAS,CAACA,EAAG,qBAAqB,CAACU,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOf,EAAIgB,SAASC,KAAK,gBAAgBb,EAAG,QAAQ,CAACU,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOf,EAAIgB,SAASC,KAAK,mBAAmB,CAACjB,EAAIkB,GAAG,eAAed,EAAG,QAAQ,CAACU,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOf,EAAIgB,SAASC,KAAK,qBAAqB,CAACjB,EAAIkB,GAAG,iBAAiBd,EAAG,QAAQ,CAACU,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOf,EAAIgB,SAASC,KAAK,+BAA+B,CAACjB,EAAIkB,GAAG,2BAA2Bd,EAAG,QAAQ,CAACU,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOf,EAAIgB,SAASC,KAAK,mBAAmB,CAACjB,EAAIkB,GAAG,eAAed,EAAG,QAAQ,CAACU,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOf,EAAIgB,SAASC,KAAK,2BAA2B,CAACjB,EAAIkB,GAAG,uBAAuBd,EAAG,QAAQ,CAACU,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOf,EAAIgB,SAASC,KAAK,qBAAqB,CAACjB,EAAIkB,GAAG,kBAAkB,KAAKC,OAAM,OAAUf,EAAG,SAAS,CAACA,EAAG,gBAAgB,IAAI,IACv7BgB,EAAkB,GCHlB,EAAS,WAAa,IAAIpB,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,cAAc,CAACiB,YAAY,YAAYf,MAAM,CAAC,MAAQ,GAAG,MAAQ,GAAG,GAAK,YAAY,CAACF,EAAG,QAAQ,CAACE,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,WAAW,CAACF,EAAG,aAAa,CAACiB,YAAY,cAAcC,YAAY,CAAC,YAAY,UAAUhB,MAAM,CAAC,OAAS,MAAM,IAAM,EAAQ,QAAyB,CAACF,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,MAAQ,QAAQ,QAAU,WAAW,CAACF,EAAG,QAAQ,CAACiB,YAAY,cAAcf,MAAM,CAAC,KAAO,OAAO,CAACF,EAAG,KAAK,CAACiB,YAAY,iCAAiC,CAACrB,EAAIkB,GAAG,aAAad,EAAG,KAAK,CAACiB,YAAY,mCAAmC,CAACjB,EAAG,OAAO,CAACJ,EAAIkB,GAAG,yDAAyDd,EAAG,KAAK,CAACiB,YAAY,mCAAmC,CAACrB,EAAIkB,GAAG,2BAA2B,IAAI,IAAI,GAAGd,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,SAAS,MAAQ,GAAG,GAAK,gBAAgB,CAACF,EAAG,KAAK,CAACiB,YAAY,iCAAiC,CAACrB,EAAIkB,GAAG,kBAAkBd,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,WAAW,CAACF,EAAG,IAAI,CAACiB,YAAY,gBAAgB,CAACjB,EAAG,IAAI,CAACJ,EAAIkB,GAAG,6BAA6BlB,EAAIkB,GAAG,0QAA0Qd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,gCAAgClB,EAAIkB,GAAG,ieAAied,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,SAAS,MAAQ,GAAG,GAAK,kBAAkB,CAACF,EAAG,KAAK,CAACiB,YAAY,iCAAiC,CAACrB,EAAIkB,GAAG,oBAAoBd,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,WAAW,CAACF,EAAG,IAAI,CAACiB,YAAY,gBAAgB,CAACrB,EAAIkB,GAAG,gnBAAgnBd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,6EAA6ElB,EAAIkB,GAAG,mCAAmCd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,yBAAyBlB,EAAIkB,GAAG,kpBAAkpBd,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,SAAS,MAAQ,GAAG,GAAK,4BAA4B,CAACF,EAAG,KAAK,CAACiB,YAAY,iCAAiC,CAACrB,EAAIkB,GAAG,8BAA8Bd,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,WAAW,CAACF,EAAG,IAAI,CAACiB,YAAY,gBAAgB,CAACrB,EAAIkB,GAAG,q0BAAq0Bd,EAAG,KAAK,CAACA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACJ,EAAIkB,GAAG,uCAAuClB,EAAIkB,GAAG,41BAA41Bd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,6BAA6BlB,EAAIkB,GAAG,WAAWd,EAAG,MAAMA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACJ,EAAIkB,GAAG,2CAA2ClB,EAAIkB,GAAG,qIAAqId,EAAG,IAAI,CAACJ,EAAIkB,GAAG,gBAAgBlB,EAAIkB,GAAG,0RAA0Rd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,kBAAkBlB,EAAIkB,GAAG,khBAAkhBd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,6BAA6BlB,EAAIkB,GAAG,WAAWd,EAAG,MAAMA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACJ,EAAIkB,GAAG,+EAA+ElB,EAAIkB,GAAG,KAAKd,EAAG,MAAM,CAACE,MAAM,CAAC,IAAM,EAAQ,KAAqB,MAAQ,QAAQ,MAAQ,MAAM,OAAS,SAASN,EAAIkB,GAAG,+mBAA+mBd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,WAAWlB,EAAIkB,GAAG,kZAAkZd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,6BAA6BlB,EAAIkB,GAAG,aAAad,EAAG,MAAMA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACJ,EAAIkB,GAAG,+DAA+DlB,EAAIkB,GAAG,4KAA4Kd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,cAAclB,EAAIkB,GAAG,obAAobd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,6BAA6BlB,EAAIkB,GAAG,WAAWd,EAAG,MAAMA,EAAG,KAAK,CAACA,EAAG,IAAI,CAACJ,EAAIkB,GAAG,6FAA6FlB,EAAIkB,GAAG,KAAKd,EAAG,MAAM,CAACE,MAAM,CAAC,IAAM,EAAQ,MAA4B,MAAQ,QAAQ,MAAQ,MAAM,OAAS,SAASN,EAAIkB,GAAG,osBAAosBd,EAAG,IAAI,CAACJ,EAAIkB,GAAG,6BAA6BlB,EAAIkB,GAAG,eAAed,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,SAAS,MAAQ,GAAG,GAAK,gBAAgB,CAACF,EAAG,KAAK,CAACiB,YAAY,iCAAiC,CAACrB,EAAIkB,GAAG,kBAAkBd,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,MAAQ,SAAS,QAAU,SAAS,aAAa,KAAK,CAACN,EAAIuB,GAAIvB,EAAW,SAAE,SAASwB,EAAOC,GAAK,MAAO,CAACrB,EAAG,iBAAiB,CAACK,IAAIgB,EAAInB,MAAM,CAAC,OAASkB,UAAc,GAAGpB,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,SAAS,MAAQ,GAAG,GAAK,wBAAwB,CAACF,EAAG,KAAK,CAACiB,YAAY,iCAAiC,CAACrB,EAAIkB,GAAG,0BAA0Bd,EAAG,QAAQ,CAACiB,YAAY,iBAAiBf,MAAM,CAAC,MAAQ,SAAS,QAAU,SAAS,aAAa,KAAK,CAACF,EAAG,aAAaJ,EAAIuB,GAAIvB,EAAgB,cAAE,SAAS0B,EAAKC,GAAG,OAAOvB,EAAG,kBAAkB,CAACK,IAAIkB,EAAErB,MAAM,CAAC,MAAQoB,EAAKE,MAAM,MAAQ,IAAIrB,YAAYP,EAAIQ,GAAG,CAAC,CAACC,IAAI,WAAWC,GAAG,WAAW,MAAO,CAACN,EAAG,OAAO,CAACyB,MAAO,6BAAgCH,EAAU,MAAI,SAAUI,SAAS,CAAC,YAAc9B,EAAI+B,GAAGL,EAAKM,WAAWb,OAAM,IAAO,MAAK,IAAO,CAACf,EAAG,MAAM,CAACiB,YAAY,QAAQ,CAACjB,EAAG,KAAK,CAACyB,MAAO,mCAAsCH,EAAU,MAAI,UAAW,CAAC1B,EAAIkB,GAAG,IAAIlB,EAAI+B,GAAGL,EAAKO,OAAO,OAAO7B,EAAG,MAAM,CAACJ,EAAIkB,GAAG,IAAIlB,EAAI+B,GAAGL,EAAKQ,aAAa,cAAa,IAAI,GAAG9B,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,SAAS,MAAQ,GAAG,GAAK,kBAAkB,CAACF,EAAG,KAAK,CAACiB,YAAY,iCAAiC,CAACrB,EAAIkB,GAAG,oBAAoBd,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,WAAW,CAACF,EAAG,IAAI,CAACiB,YAAY,gBAAgB,CAACjB,EAAG,KAAK,CAACA,EAAG,KAAK,CAACJ,EAAIkB,GAAG,gKAAgKd,EAAG,KAAK,CAACJ,EAAIkB,GAAG,sGAAsGd,EAAG,KAAK,CAACJ,EAAIkB,GAAG,qCAAqCd,EAAG,IAAI,CAACE,MAAM,CAAC,KAAO,mFAAmF,OAAS,WAAW,CAACN,EAAIkB,GAAG,yEAAyElB,EAAIkB,GAAG,kBAAkBd,EAAG,KAAK,CAACJ,EAAIkB,GAAG,6JAA6Jd,EAAG,KAAK,CAACJ,EAAIkB,GAAG,kLAAkLd,EAAG,KAAK,CAACJ,EAAIkB,GAAG,wKAAwKd,EAAG,KAAK,CAACJ,EAAIkB,GAAG,4IAA4Id,EAAG,QAAQ,CAACiB,YAAY,OAAOf,MAAM,CAAC,aAAa,GAAG,MAAQ,SAAS,QAAU,aAAa,IACpla,EAAkB,GCDlB,EAAS,WAAa,IAAIN,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,SAAS,CAACiB,YAAY,UAAUf,MAAM,CAAC,YAAY,QAAQ,CAACF,EAAG,QAAQ,CAACE,MAAM,CAAC,IAAMN,EAAImC,UAAU,OAAS,WAAW/B,EAAG,eAAe,CAACJ,EAAIkB,GAAG,IAAIlB,EAAI+B,GAAG/B,EAAIoC,OAAOC,MAAM,OAAOjC,EAAG,kBAAkB,CAACJ,EAAIkB,GAAG,IAAIlB,EAAI+B,GAAG/B,EAAIoC,OAAOE,SAAS,OAAOlC,EAAG,iBAAiB,CAACA,EAAG,QAAQ,CAACE,MAAM,CAAC,MAAQ,mBAAmB,KAAO,KAAK,CAACN,EAAIkB,GAAG,iBAAiBd,EAAG,YAAYA,EAAG,QAAQ,CAACE,MAAM,CAAC,KAAO,IAAIQ,GAAG,CAAC,MAAQ,SAASC,GAAQf,EAAIuC,MAAQvC,EAAIuC,QAAQ,CAACnC,EAAG,SAAS,CAACJ,EAAIkB,GAAGlB,EAAI+B,GAAG/B,EAAIuC,KAAO,iBAAmB,wBAAwB,IAAI,GAAGnC,EAAG,sBAAsB,CAACA,EAAG,MAAM,CAACoC,WAAW,CAAC,CAACH,KAAK,OAAOI,QAAQ,SAASC,MAAO1C,EAAQ,KAAE2C,WAAW,UAAU,CAACvC,EAAG,aAAaA,EAAG,cAAc,CAACJ,EAAIkB,GAAG,IAAIlB,EAAI+B,GAAG/B,EAAIoC,OAAOQ,WAAW,QAAQ,MAAM,IACt0B,EAAkB,GCgDtB,GACE,KAAFP,gBACE,MAAFzB,CACA,UAEE,OACE,MAAJ,CACM,UAANiC,EACM,MAANN,IAGE,SAAFO,CACI,YACE,IAAN,OACM,IACEX,EAAYA,EAAAA,KAAAA,CAAQA,KAAelC,KAAKmC,OAAOD,WACvD,MACQ,EAARA,sDAEM,OAAN,IAGE,YAGA,QAAFY,IC1EuS,I,0GCOnSC,GAAY,OACd,EACA,EACA,GACA,EACA,KACA,WACA,MAIF,EAAeA,EAAiB,QAehC,IAAkBA,EAAW,CAACC,KAAI,UAAM,iBAAa,mBAAc,eAAU,gBAAW,cAAS,sBAAkB,WAAM,SAAK,YAAQ,MCoKtI,OACEC,WAAY,CACVC,cAAaA,GAEf,KAAFd,cAEE,KAAFe,KAAAA,CACI,QAAJC,CACA,CACM,KAANhB,wBACM,UAANF,aACM,QAANG,8CACM,UAANgB,GACM,UAANV,ieAEA,CACM,KAANP,cACM,UAANF,YACM,QAANG,iBACM,UAANgB,GACM,UAANV,yaAEA,CACM,KAANP,kBACM,UAANF,iBACM,QAANG,sCACM,UAANgB,GACM,UAANV,wcAEA,CACM,KAANP,kBACM,UAANF,aACM,QAANG,2CACM,UAANgB,GACM,UAANV,khBAEA,CACM,KAANP,aACM,UAANF,aACM,QAANG,8CACM,UAANgB,GACM,UAANV,ilBAGI,aAAJW,CACA,CACM,MAAN3B,MAEM,MAANK,6CACM,YAANC,IAEA,CACM,MAANN,SAEM,MAANK,sCACM,YAANC,IAEA,CACM,MAANN,QAEM,MAANK,2CACM,YAANC,IAEA,CACM,MAANN,SAEM,MAANK,gDACM,YAANC,IAEA,CACM,MAANN,OAEM,MAANK,gDACM,YAANC,QC9QqS,I,4DCQjS,GAAY,OACd,EACA,EACA,GACA,EACA,KACA,KACA,MAIF,EAAe,EAAiB,QAUhC,IAAkB,EAAW,CAACsB,KAAI,eAAW,cAAU,SAAK,cAAU,kBAAc,MC4BpF,OACEnB,KAAM,MAENa,WAAY,CACVO,YAAWA,GAGbL,KAAM,KAAM,KChEsQ,I,4DCOhR,GAAY,OACd,EACArD,EACAqB,GACA,EACA,KACA,KACA,MAIF,EAAe,EAAiB,QAWhC,IAAkB,EAAW,CAACsC,KAAI,YAAQ,mBAAe,SAAK,UAAM,SAAK,UAAM,M,cC1B/EC,EAAAA,EAAAA,IAAQC,EAAAA,GAER,UAAmBA,EAAAA,EAAQ,ICD3BD,EAAAA,EAAAA,OAAAA,eAA2B,EAE3B,IAAIA,EAAAA,EAAI,CACNE,QADM,EAEN9D,OAAQ+D,GAAKA,EAAEC,KACdC,OAAO,S,qBCTV,IAAIC,EAAM,CACT,cAAe,KACf,eAAgB,KAChB,mBAAoB,KACpB,cAAe,KACf,eAAgB,KAChB,eAAgB,KAChB,kBAAmB,KACnB,mBAAoB,KACpB,cAAe,KACf,yBAA0B,KAC1B,YAAa,IACb,aAAc,KACd,aAAc,KACd,mBAAoB,MAIrB,SAASC,EAAeC,GACvB,IAAIC,EAAKC,EAAsBF,GAC/B,OAAOG,EAAoBF,GAE5B,SAASC,EAAsBF,GAC9B,IAAIG,EAAoBC,EAAEN,EAAKE,GAAM,CACpC,IAAIK,EAAI,IAAIC,MAAM,uBAAyBN,EAAM,KAEjD,MADAK,EAAEE,KAAO,mBACHF,EAEP,OAAOP,EAAIE,GAEZD,EAAeS,KAAO,WACrB,OAAOC,OAAOD,KAAKV,IAEpBC,EAAeW,QAAUR,EACzBS,EAAOC,QAAUb,EACjBA,EAAeE,GAAK,M,88TClChBY,EAA2B,GAG/B,SAASV,EAAoBW,GAE5B,IAAIC,EAAeF,EAAyBC,GAC5C,QAAqBE,IAAjBD,EACH,OAAOA,EAAaH,QAGrB,IAAID,EAASE,EAAyBC,GAAY,CAGjDF,QAAS,IAOV,OAHAK,EAAoBH,GAAUH,EAAQA,EAAOC,QAAST,GAG/CQ,EAAOC,QAIfT,EAAoBe,EAAID,E,WCzBxB,IAAIE,EAAW,GACfhB,EAAoBiB,EAAI,SAASC,EAAQC,EAAU/E,EAAIgF,GACtD,IAAGD,EAAH,CAMA,IAAIE,EAAeC,EAAAA,EACnB,IAASjE,EAAI,EAAGA,EAAI2D,EAASO,OAAQlE,IAAK,CACrC8D,EAAWH,EAAS3D,GAAG,GACvBjB,EAAK4E,EAAS3D,GAAG,GACjB+D,EAAWJ,EAAS3D,GAAG,GAE3B,IAJA,IAGImE,GAAY,EACPC,EAAI,EAAGA,EAAIN,EAASI,OAAQE,MACpB,EAAXL,GAAsBC,GAAgBD,IAAad,OAAOD,KAAKL,EAAoBiB,GAAGS,OAAM,SAASvF,GAAO,OAAO6D,EAAoBiB,EAAE9E,GAAKgF,EAASM,OAC3JN,EAASQ,OAAOF,IAAK,IAErBD,GAAY,EACTJ,EAAWC,IAAcA,EAAeD,IAG7C,GAAGI,EAAW,CACbR,EAASW,OAAOtE,IAAK,GACrB,IAAIuE,EAAIxF,SACEyE,IAANe,IAAiBV,EAASU,IAGhC,OAAOV,EAzBNE,EAAWA,GAAY,EACvB,IAAI,IAAI/D,EAAI2D,EAASO,OAAQlE,EAAI,GAAK2D,EAAS3D,EAAI,GAAG,GAAK+D,EAAU/D,IAAK2D,EAAS3D,GAAK2D,EAAS3D,EAAI,GACrG2D,EAAS3D,GAAK,CAAC8D,EAAU/E,EAAIgF,I,cCJ/BpB,EAAoB6B,EAAI,SAASrB,GAChC,IAAIsB,EAAStB,GAAUA,EAAOuB,WAC7B,WAAa,OAAOvB,EAAO,YAC3B,WAAa,OAAOA,GAErB,OADAR,EAAoBgC,EAAEF,EAAQ,CAAEG,EAAGH,IAC5BA,G,cCLR9B,EAAoBgC,EAAI,SAASvB,EAASyB,GACzC,IAAI,IAAI/F,KAAO+F,EACXlC,EAAoBC,EAAEiC,EAAY/F,KAAS6D,EAAoBC,EAAEQ,EAAStE,IAC5EmE,OAAO6B,eAAe1B,EAAStE,EAAK,CAAEiG,YAAY,EAAMC,IAAKH,EAAW/F,M,cCJ3E6D,EAAoBsC,EAAI,WACvB,GAA0B,kBAAfC,WAAyB,OAAOA,WAC3C,IACC,OAAO5G,MAAQ,IAAI6G,SAAS,cAAb,GACd,MAAOtC,GACR,GAAsB,kBAAXuC,OAAqB,OAAOA,QALjB,G,cCAxBzC,EAAoBC,EAAI,SAASyC,EAAKC,GAAQ,OAAOrC,OAAOsC,UAAUC,eAAeC,KAAKJ,EAAKC,I,cCC/F3C,EAAoB4B,EAAI,SAASnB,GACX,qBAAXsC,QAA0BA,OAAOC,aAC1C1C,OAAO6B,eAAe1B,EAASsC,OAAOC,YAAa,CAAE5E,MAAO,WAE7DkC,OAAO6B,eAAe1B,EAAS,aAAc,CAAErC,OAAO,K,cCLvD4B,EAAoBiD,EAAI,S,cCKxB,IAAIC,EAAkB,CACrB,IAAK,GAaNlD,EAAoBiB,EAAEQ,EAAI,SAAS0B,GAAW,OAAoC,IAA7BD,EAAgBC,IAGrE,IAAIC,EAAuB,SAASC,EAA4BvE,GAC/D,IAKI6B,EAAUwC,EALVhC,EAAWrC,EAAK,GAChBwE,EAAcxE,EAAK,GACnByE,EAAUzE,EAAK,GAGIzB,EAAI,EAC3B,GAAG8D,EAASqC,MAAK,SAAS1D,GAAM,OAA+B,IAAxBoD,EAAgBpD,MAAe,CACrE,IAAIa,KAAY2C,EACZtD,EAAoBC,EAAEqD,EAAa3C,KACrCX,EAAoBe,EAAEJ,GAAY2C,EAAY3C,IAGhD,GAAG4C,EAAS,IAAIrC,EAASqC,EAAQvD,GAGlC,IADGqD,GAA4BA,EAA2BvE,GACrDzB,EAAI8D,EAASI,OAAQlE,IACzB8F,EAAUhC,EAAS9D,GAChB2C,EAAoBC,EAAEiD,EAAiBC,IAAYD,EAAgBC,IACrED,EAAgBC,GAAS,KAE1BD,EAAgBC,GAAW,EAE5B,OAAOnD,EAAoBiB,EAAEC,IAG1BuC,EAAqBC,KAAK,qBAAuBA,KAAK,sBAAwB,GAClFD,EAAmBE,QAAQP,EAAqBQ,KAAK,KAAM,IAC3DH,EAAmBI,KAAOT,EAAqBQ,KAAK,KAAMH,EAAmBI,KAAKD,KAAKH,I,GC/CvF,IAAIK,EAAsB9D,EAAoBiB,OAAEJ,EAAW,CAAC,MAAM,WAAa,OAAOb,EAAoB,SAC1G8D,EAAsB9D,EAAoBiB,EAAE6C,I","sources":["webpack://kl4ad/./src/App.vue?6498","webpack://kl4ad/./src/components/LandingPage.vue?7f13","webpack://kl4ad/./src/components/BiographyCard.vue?72d5","webpack://kl4ad/src/components/BiographyCard.vue","webpack://kl4ad/./src/components/BiographyCard.vue?1585","webpack://kl4ad/./src/components/BiographyCard.vue","webpack://kl4ad/src/components/LandingPage.vue","webpack://kl4ad/./src/components/LandingPage.vue?107a","webpack://kl4ad/./src/components/LandingPage.vue","webpack://kl4ad/src/App.vue","webpack://kl4ad/./src/App.vue?405d","webpack://kl4ad/./src/App.vue","webpack://kl4ad/./src/plugins/vuetify.js","webpack://kl4ad/./src/main.js","webpack://kl4ad/./src/assets/ sync ^\\.\\/.*$","webpack://kl4ad/webpack/bootstrap","webpack://kl4ad/webpack/runtime/chunk loaded","webpack://kl4ad/webpack/runtime/compat get default export","webpack://kl4ad/webpack/runtime/define property getters","webpack://kl4ad/webpack/runtime/global","webpack://kl4ad/webpack/runtime/hasOwnProperty shorthand","webpack://kl4ad/webpack/runtime/make namespace object","webpack://kl4ad/webpack/runtime/publicPath","webpack://kl4ad/webpack/runtime/jsonp chunk loading","webpack://kl4ad/webpack/startup"],"sourcesContent":["var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('v-app',[_c('v-app-bar',{attrs:{\"app\":\"\",\"fixed\":\"\",\"height\":\"8\",\"dark\":\"\",\"color\":\"#4b296b\"},scopedSlots:_vm._u([{key:\"img\",fn:function(ref){\nvar props = ref.props;\nreturn [_c('v-img',_vm._b({},'v-img',props,false))]}},{key:\"extension\",fn:function(){return [_c('v-tabs',[_c('v-app-bar-nav-icon',{on:{\"click\":function($event){return _vm.$vuetify.goTo('#main_id')}}}),_c('v-tab',{on:{\"click\":function($event){return _vm.$vuetify.goTo('#abstract_id')}}},[_vm._v(\" Abstract\")]),_c('v-tab',{on:{\"click\":function($event){return _vm.$vuetify.goTo('#motivation_id')}}},[_vm._v(\" Motivation\")]),_c('v-tab',{on:{\"click\":function($event){return _vm.$vuetify.goTo('#detailed_description_id')}}},[_vm._v(\" Detailed Description\")]),_c('v-tab',{on:{\"click\":function($event){return _vm.$vuetify.goTo('#speakers_id')}}},[_vm._v(\" Speakers\")]),_c('v-tab',{on:{\"click\":function($event){return _vm.$vuetify.goTo('#tutorial_program_id')}}},[_vm._v(\" Tutorial Program\")]),_c('v-tab',{on:{\"click\":function($event){return _vm.$vuetify.goTo('#references_id')}}},[_vm._v(\" References\")])],1)]},proxy:true}])}),_c('v-main',[_c('LandingPage')],1)],1)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('v-container',{staticClass:\"pa-0 ma-0\",attrs:{\"fluid\":\"\",\"about\":\"\",\"id\":\"main_id\"}},[_c('v-row',{attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\"}},[_c('v-parallax',{staticClass:\"start-image\",staticStyle:{\"max-width\":\"1980px\"},attrs:{\"height\":\"325\",\"src\":require(\"../assets/Title.png\")}},[_c('v-row',{staticClass:\"mt-2\",attrs:{\"align\":\"start\",\"justify\":\"center\"}},[_c('v-col',{staticClass:\"text-center\",attrs:{\"cols\":\"12\"}},[_c('h1',{staticClass:\"text-h1 font-weight-thin mb-4\"},[_vm._v(\" KL4AD \")]),_c('h4',{staticClass:\"heading-text text-h4 subheading\"},[_c('span',[_vm._v(\"Knowledge-Infused Learning for Autonomous Driving\")])]),_c('h5',{staticClass:\"heading-text text-h5 subheading\"},[_vm._v(\" ISWC'22 Tutorial \")])])],1)],1)],1),_c('v-row',{staticClass:\"pt-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\",\"about\":\"\",\"id\":\"abstract_id\"}},[_c('h1',{staticClass:\"text-h4 font-weight-thin mb-4\"},[_vm._v(\" Abstract \")])]),_c('v-row',{staticClass:\"pa-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\"}},[_c('p',{staticClass:\"text-justify\"},[_c('b',[_vm._v(\"Autonomous Driving (AD)\")]),_vm._v(\" is considered as a testbed for tackling many hard AI problems. Despite the recent advancements in the field, AD is still far from achieving full autonomy due to core technical problems inherent in AD. The emerging field of neuro-symbolic AI and the methods for \"),_c('b',[_vm._v(\"knowledge-infused learning\")]),_vm._v(\" are showing exciting ways of leveraging external knowledge within machine/deep learning solutions, with the potential benefits for interpretability, explainability, robustness, and transferability. In this tutorial, we will examine the use of knowledge-infused learning for three core state-of-the-art technical achievements within the AD domain. With a collaborative team from both academia and industry, we will demonstrate recent innovations using real-world datasets. \")])]),_c('v-row',{staticClass:\"pt-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\",\"about\":\"\",\"id\":\"motivation_id\"}},[_c('h1',{staticClass:\"text-h4 font-weight-thin mb-4\"},[_vm._v(\" Motivation \")])]),_c('v-row',{staticClass:\"pa-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\"}},[_c('p',{staticClass:\"text-justify\"},[_vm._v(\" To realize the vision of autonomous driving, the automotive industry is investing heavily into core AI technologies and deploying fleets of vehicles across the world to collect massive amounts of data, including – but not limited to – video, LIDAR, and RADAR. To manage these vast amounts of data, companies are beginning to experiment with the use of KGs, which are capable of representing meaningful relations between entities in the world while helping to enable the principles of FAIR data – i.e. findability, accessibility, interoperability, and re-use. Simultaneously, current research into the emerging topic of \"),_c('b',[_vm._v(\"knowledge-infused learning [1] -- or more generally, neuro-symbolic AI \")]),_vm._v(\", which is often dubbed as the \"),_c('b',[_vm._v(\" 3rd wave of AI [2]\")]),_vm._v(\" -- is showing new and exciting uses for KGs in AI applications. Knowledge-infused learning proposes intuitive ways of leveraging knowledge graphs within machine/deep learning solutions. This infusion of knowledge has been shown to improve the predictive capabilities of ML/DL while providing great potential for improving interpretability, explainability, robustness, and transferability. For these reasons, knowledge-infused learning holds much promise for helping to meet the complex technical challenges of autonomous driving (AD). In this tutorial, we will focus on three distinct technical innovations that leverage knowledge-infused learning. \")])]),_c('v-row',{staticClass:\"pt-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\",\"about\":\"\",\"id\":\"detailed_description_id\"}},[_c('h1',{staticClass:\"text-h4 font-weight-thin mb-4\"},[_vm._v(\" Detailed Description \")])]),_c('v-row',{staticClass:\"pa-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\"}},[_c('p',{staticClass:\"text-justify\"},[_vm._v(\" We seek to provide an overview of knowledge-infused learning, an examination of its use for autonomous driving, and three deep dives into current state-of-the-art technical achievements. Specifically, the tutorial will consist of 5 interconnected lecture modules; two 30 mins introductory modules followed by three 40 mins modules for each application. The audience is expected to have a basic understanding of deep/machine learning, semantic technologies (e.g., RDF, OWL, linked open data) and semantic embedding approaches. We aim to guide attendees through a high-level tour of the knowledge-infused learning methods, basic familiarity into open-domain autonomous driving datasets/challenges, and the process of solving domain problems using neuro-symbolic AI methods. We'll be covering the following modules in this tutorial. \")]),_c('ul',[_c('li',[_c('b',[_vm._v(\"Knowledge-infused Learning (KL): \")]),_vm._v(\" KL a form of neuro-symbolic AI is a novel paradigm that seeks to incorporate a variety of explicit (symbolic) knowledge into a data-driven statistical AI framework that supports advancement in machine intelligence. Utilizing knowledge and data in deep learning models to enable learning from lower-level syntactic and lexical features from data through statistical (deep) learning as well as higher-level concepts from knowledge. Using knowledge also allows greater transparency in the decision-making, and enables explanations that users need for informed decision making. Recently, researchers have categorized the recent approaches into a continuum that comprises of three stages; namely, shallow, semi-deep, and deep infusion. We will provide a detailed overview for each stage of knowledge infusion with examples across several application domains. (\"),_c('i',[_vm._v(\"See relevant resources:\")]),_vm._v(\" [1])\")]),_c('br'),_c('li',[_c('b',[_vm._v(\"Applications for Autonomous Driving: \")]),_vm._v(\" Despite recent advancements, AD is still far from ready to meet full level-5 autonomy requirements. The primary obstacle is the \"),_c('i',[_vm._v(\"open-world\")]),_vm._v(\" environment in which the autonomous vehicle must operate. Navigating this environment requires making informed decisions and taking actions within novel and complex situations. While machine learning, in general, and autonomous driving, in particular, have had much success in \"),_c('i',[_vm._v(\"closed-world\")]),_vm._v(\" environments with lots of experiential training data, the challenges posed by an open-world environment are yet to be resolved. Additionally, the full autonomy of self-driving and its widespread usage poses a new set of non-technical challenges, including user acceptance, accountability, explainability, and conformance to legal, ethical, and societal boundaries. We believe that knowledge-infused learning -- through an integration of domain knowledge and machine learning -- is a potent tool to overcome such challenges. (\"),_c('i',[_vm._v(\"See relevant resources:\")]),_vm._v(\" [3])\")]),_c('br'),_c('li',[_c('b',[_vm._v(\"Knowledge-based Entity Prediction (KEP) for Improved Machine Perception: \")]),_vm._v(\" \"),_c('img',{attrs:{\"src\":require(\"../assets/kep.png\"),\"align\":\"right\",\"width\":\"330\",\"height\":\"200\"}}),_vm._v(\" Machine perception is one of the key technical problems in AD where detecting and recognizing objects/events in a scene (i.e. environmental perception) is a critical task. This, however, is particularly challenging as there are several reasons why an entity could go unrecognized. This includes, but not limited to, sensor failure, occlusion, low resolution (e.g., from weather), or errors in computer vision models. For example, consider the case where an ego vehicle driving through a residential neighborhood and detects only a ball on the road (partial observation) and could contain unrecognized entities such as \"),_c('i',[_vm._v(\"Child\")]),_vm._v(\" in the scene. Knowledge-based entity prediction (KEP) is a novel task that aims to address this issue by leveraging relational knowledge from heterogeneous sources in predicting potentially unrecognized entities. We will show how an innovative knowledge-infused learning approach can be developed for KEP and demonstrate its usefulness considering two high-quality, large-scale real AD datasets. (\"),_c('i',[_vm._v(\"See relevant resources:\")]),_vm._v(\" [4,5])\")]),_c('br'),_c('li',[_c('b',[_vm._v(\"Leveraging Commonsense for Explainable Scene Clustering: \")]),_vm._v(\" The task of scene clustering refers to clustering a given set of scenes and assigning descriptive label(s) to each cluster. For example, a cluster may be described as \"),_c('i',[_vm._v(\"accident\")]),_vm._v(\" scenes with a crashed vehicle, a police car, and an ambulance. Using scenes represented in a knowledge graph, and enriched with commonsense knowledge, it may be possible to automatically generate explanations for semantic clusters. In this tutorial, we will demonstrate how an innovative approach can be developed for explainable scene clustering along with the process of leveraging relevant commonsense knowledge for this task. (\"),_c('i',[_vm._v(\"See relevant resources:\")]),_vm._v(\" [6])\")]),_c('br'),_c('li',[_c('b',[_vm._v(\"Learning Visual Models for Road Sign Recognition using a Knowledge Graph as a Trainer: \")]),_vm._v(\" \"),_c('img',{attrs:{\"src\":require(\"../assets/road_signs.png\"),\"align\":\"right\",\"width\":\"370\",\"height\":\"150\"}}),_vm._v(\" The task of recognizing and understanding road signs is an important feature of autonomous driving. Current technology for road sign recognition (RSR) is mainly based on computer vision (CV) algorithms that solely depend on image data distribution of the training domain. Such models, however, tend to fail when applied to a target domain (e.g., road signs from China) that differs from their source domain (e.g. road signs from Germany). Knowledge graph neural network (KG-NN) is a novel neuro-symbolic approach to address the problem of transfer learning by using image-data-invariant auxiliary knowledge. We will show how this technology can be applied to enable transfer learning for the RSR task. (\"),_c('i',[_vm._v(\"See relevant resources:\")]),_vm._v(\" [7])\")])])]),_c('v-row',{staticClass:\"pt-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\",\"about\":\"\",\"id\":\"speakers_id\"}},[_c('h1',{staticClass:\"text-h4 font-weight-thin mb-4\"},[_vm._v(\" Speakers \")])]),_c('v-row',{staticClass:\"pb-8\",attrs:{\"align\":\"center\",\"justify\":\"center\",\"no-gutters\":\"\"}},[_vm._l((_vm.authors),function(author,idx){return [_c('biography-card',{key:idx,attrs:{\"person\":author}})]})],2),_c('v-row',{staticClass:\"pt-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\",\"about\":\"\",\"id\":\"tutorial_program_id\"}},[_c('h1',{staticClass:\"text-h4 font-weight-thin mb-4\"},[_vm._v(\" Tutorial Program \")])]),_c('v-row',{staticClass:\"pb-8 pr-8 pl-8\",attrs:{\"align\":\"center\",\"justify\":\"center\",\"no-gutters\":\"\"}},[_c('v-timeline',_vm._l((_vm.programItems),function(item,i){return _c('v-timeline-item',{key:i,attrs:{\"color\":item.color,\"small\":\"\"},scopedSlots:_vm._u([{key:\"opposite\",fn:function(){return [_c('span',{class:(\"headline font-weight-bold \" + (item.color) + \"--text\"),domProps:{\"textContent\":_vm._s(item.time)}})]},proxy:true}],null,true)},[_c('div',{staticClass:\"py-4\"},[_c('h2',{class:(\"headline font-weight-light mb-4 \" + (item.color) + \"--text\")},[_vm._v(\" \"+_vm._s(item.title)+\" \")]),_c('div',[_vm._v(\" \"+_vm._s(item.description)+\" \")])])])}),1)],1),_c('v-row',{staticClass:\"pt-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\",\"about\":\"\",\"id\":\"references_id\"}},[_c('h1',{staticClass:\"text-h4 font-weight-thin mb-4\"},[_vm._v(\" References \")])]),_c('v-row',{staticClass:\"pa-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\"}},[_c('p',{staticClass:\"text-justify\"},[_c('ol',[_c('li',[_vm._v(\" Sheth, A., Gaur, M., Kursuncu, U., Wickramarachchi, R.: Shades of knowledge- infused learning for enhancing deep learning. IEEE Internet Computing (2019)\")]),_c('li',[_vm._v(\"Garcez, A.d., Lamb, L.C.: Neurosymbolic ai: The 3rd wave. arXiv preprint arXiv:2012.05876 (2020)\")]),_c('li',[_vm._v(\"Henson, C., Wickramarachchi, R.: \"),_c('a',{attrs:{\"href\":\"https://www.bosch.com/stories/knowledge-infused-learning-for-autonomous-driving/\",\"target\":\"_blank\"}},[_vm._v(\" Introduction to knowledge-infused learning for autonomous driving \")]),_vm._v(\" (June 2021)\")]),_c('li',[_vm._v(\" Wickramarachchi, R., Henson, C., Sheth, A.: Knowledge-infused Learning for Entity Prediction in Driving Scenes. Frontiers in Big Data 4, 759110 (2021)\")]),_c('li',[_vm._v(\" Wickramarachchi, R., Henson, C., Sheth, A. Knowledge-based Entity Prediction for Improved Machine Perception in Autonomous Systems. arXiv preprint arXiv:2203.16616 (2022) \")]),_c('li',[_vm._v(\"Chowdhury, S.N., Wickramarachchi, R., Gad-Elrab, M.H., Stepanova, D., Henson, C.: Towards leveraging commonsense knowledge for autonomous driving. In: ISWC (2021)\")]),_c('li',[_vm._v(\" Monka, S., Halilaj, L., Schmid, S., Rettinger, A.: Learning visual models using a knowledge graph as a trainer. In: ISWC (2021)\")])])])]),_c('v-row',{staticClass:\"pa-8\",attrs:{\"no-gutters\":\"\",\"align\":\"center\",\"justify\":\"center\"}})],1)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('v-card',{staticClass:\"mx-auto\",attrs:{\"max-width\":\"344\"}},[_c('v-img',{attrs:{\"src\":_vm.imagePath,\"height\":\"200px\"}}),_c('v-card-title',[_vm._v(\" \"+_vm._s(_vm.person.name)+\" \")]),_c('v-card-subtitle',[_vm._v(\" \"+_vm._s(_vm.person.company)+\" \")]),_c('v-card-actions',[_c('v-btn',{attrs:{\"color\":\"orange lighten-2\",\"text\":\"\"}},[_vm._v(\" Biography \")]),_c('v-spacer'),_c('v-btn',{attrs:{\"icon\":\"\"},on:{\"click\":function($event){_vm.show = !_vm.show}}},[_c('v-icon',[_vm._v(_vm._s(_vm.show ? 'mdi-chevron-up' : 'mdi-chevron-down'))])],1)],1),_c('v-expand-transition',[_c('div',{directives:[{name:\"show\",rawName:\"v-show\",value:(_vm.show),expression:\"show\"}]},[_c('v-divider'),_c('v-card-text',[_vm._v(\" \"+_vm._s(_vm.person.biography)+\" \")])],1)])],1)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","<template>\n  <v-card\n    class=\"mx-auto\"\n    max-width=\"344\"\n  >\n    <v-img\n      :src=\"imagePath\"\n      height=\"200px\"\n    ></v-img>\n\n    <v-card-title>\n      {{person.name}}\n    </v-card-title>\n\n    <v-card-subtitle>\n      {{person.company}}\n    </v-card-subtitle>\n\n    <v-card-actions>\n      <v-btn\n        color=\"orange lighten-2\"\n        text\n      >\n        Biography\n      </v-btn>\n\n      <v-spacer></v-spacer>\n\n      <v-btn\n        icon\n        @click=\"show = !show\"\n      >\n        <v-icon>{{ show ? 'mdi-chevron-up' : 'mdi-chevron-down' }}</v-icon>\n      </v-btn>\n    </v-card-actions>\n\n    <v-expand-transition>\n      <div v-show=\"show\">\n        <v-divider></v-divider>\n\n        <v-card-text>\n          {{person.biography}}\n        </v-card-text>\n      </div>\n    </v-expand-transition>\n  </v-card>\n</template>\n\n<script>\n  export default {\n    name: 'BiographyCard',\n    props: [\n      \"person\"\n    ],\n    data() {\n      return {\n        randomInt: 0,\n        show: false,\n      }\n    },\n    computed: {\n      imagePath(){\n        let imagePath = null;\n        try{\n        imagePath = require('../assets/' + this.person.imagePath);\n        }catch {\n          imagePath = \"https://cdn.vuetifyjs.com/images/cards/sunshine.jpg\"\n        }\n        return imagePath\n      }\n    },\n    mounted() {\n        \n    },\n    methods: {}\n  }\n</script>\n\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style lang=\"scss\" scoped>\n\n</style>","import mod from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40[0].rules[0].use[1]!../../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./BiographyCard.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40[0].rules[0].use[1]!../../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./BiographyCard.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./BiographyCard.vue?vue&type=template&id=8118d3c8&scoped=true&\"\nimport script from \"./BiographyCard.vue?vue&type=script&lang=js&\"\nexport * from \"./BiographyCard.vue?vue&type=script&lang=js&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"8118d3c8\",\n  null\n  \n)\n\nexport default component.exports\n\n/* vuetify-loader */\nimport installComponents from \"!../../node_modules/vuetify-loader/lib/runtime/installComponents.js\"\nimport { VBtn } from 'vuetify/lib/components/VBtn';\nimport { VCard } from 'vuetify/lib/components/VCard';\nimport { VCardActions } from 'vuetify/lib/components/VCard';\nimport { VCardSubtitle } from 'vuetify/lib/components/VCard';\nimport { VCardText } from 'vuetify/lib/components/VCard';\nimport { VCardTitle } from 'vuetify/lib/components/VCard';\nimport { VDivider } from 'vuetify/lib/components/VDivider';\nimport { VExpandTransition } from 'vuetify/lib/components/transitions';\nimport { VIcon } from 'vuetify/lib/components/VIcon';\nimport { VImg } from 'vuetify/lib/components/VImg';\nimport { VSpacer } from 'vuetify/lib/components/VGrid';\ninstallComponents(component, {VBtn,VCard,VCardActions,VCardSubtitle,VCardText,VCardTitle,VDivider,VExpandTransition,VIcon,VImg,VSpacer})\n","<template>\n  <v-container\n  fluid\n  class=\"pa-0 ma-0\"\n  about id=\"main_id\">\n    <v-row  \n        no-gutters\n        align=\"center\"\n        justify=\"center\">\n      <v-parallax height=\"325\"\n       style=\"max-width: 1980px;\"\n       class=\"start-image\" src=\"../assets/Title.png\">\n        <v-row\n          class=\"mt-2\"\n          align=\"start\"\n          justify=\"center\"\n        >\n          <v-col\n            class=\"text-center\"\n            cols=\"12\"\n          >\n            <h1 class=\"text-h1 font-weight-thin mb-4\">\n              KL4AD\n            </h1>\n            <h4 class=\"heading-text text-h4 subheading\">\n              <span>Knowledge-Infused Learning for Autonomous Driving</span>\n            </h4>\n            <h5 class=\"heading-text text-h5 subheading\">\n              ISWC'22 Tutorial\n            </h5>\n          </v-col>\n        </v-row>\n      </v-parallax>\n    </v-row>\n    <v-row no-gutters \n      class=\"pt-8\"\n      align=\"center\"\n      justify=\"center\"\n      about id=\"abstract_id\">\n      <h1 class=\"text-h4 font-weight-thin mb-4\">\n              Abstract\n      </h1>\n    </v-row>\n      <v-row no-gutters\n        class=\"pa-8\"\n        align=\"center\"\n        justify=\"center\">\n        <p class=\"text-justify\">\n      <b>Autonomous Driving (AD)</b> is considered as a testbed for tackling many hard AI problems. Despite the recent advancements in the field, AD is still far from achieving full autonomy due to core technical problems inherent in AD. The emerging field of neuro-symbolic AI and the methods for <b>knowledge-infused learning</b> are showing exciting ways of leveraging external knowledge within machine/deep learning solutions, with the potential benefits for interpretability, explainability, robustness, and transferability. In this tutorial, we will examine the use of knowledge-infused learning for three core state-of-the-art technical achievements within the AD domain. With a collaborative team from both academia and industry, we will demonstrate recent innovations using real-world datasets.\n    </p>\n      </v-row>\n  \n  <v-row no-gutters \n      class=\"pt-8\"\n      align=\"center\"\n      justify=\"center\"\n      about id=\"motivation_id\">\n      <h1 class=\"text-h4 font-weight-thin mb-4\">\n              Motivation\n      </h1>\n    </v-row>\n      <v-row no-gutters\n      class=\"pa-8\"\n      align=\"center\"\n      justify=\"center\">\n      <p class=\"text-justify\">\nTo realize the vision of autonomous driving, the automotive industry is investing heavily into core AI technologies and deploying fleets of vehicles across the world to collect massive amounts of data, including – but not limited to – video, LIDAR, and RADAR. To manage these vast amounts of data, companies are beginning to experiment with the use of KGs, which are capable of representing meaningful relations between entities in the world while helping to enable the principles of FAIR data – i.e. findability, accessibility, interoperability, and re-use. Simultaneously, current research into the emerging topic of <b>knowledge-infused learning  [1] -- or more generally, neuro-symbolic AI </b>, which is often dubbed as the <b> 3rd wave of AI [2]</b> -- is showing new and exciting uses for KGs in AI applications.  Knowledge-infused learning proposes intuitive ways of leveraging knowledge graphs within machine/deep learning solutions. This infusion of knowledge has been shown to improve the predictive capabilities of ML/DL while providing great potential for improving interpretability, explainability, robustness, and transferability. For these reasons, knowledge-infused learning holds much promise for helping to meet the complex technical challenges of autonomous driving (AD). In this tutorial, we will focus on three distinct technical innovations that leverage knowledge-infused learning. \n  </p>\n    </v-row>\n\n\n <v-row no-gutters \n      class=\"pt-8\"\n      align=\"center\"\n      justify=\"center\"\n      about id=\"detailed_description_id\">\n      <h1 class=\"text-h4 font-weight-thin mb-4\">\n              Detailed Description\n      </h1>\n    </v-row>\n      <v-row no-gutters\n      class=\"pa-8\"\n      align=\"center\"\n      justify=\"center\">\n      <p class=\"text-justify\">\n         \n We seek to provide an overview of knowledge-infused learning, an examination of its use for autonomous driving, and three deep dives into current state-of-the-art technical achievements. Specifically, the tutorial will consist of 5 interconnected lecture modules; two 30 mins introductory modules followed by three 40 mins modules for each application. The audience is expected to have a basic understanding of deep/machine learning, semantic technologies (e.g., RDF, OWL, linked open data) and semantic embedding approaches. We aim to guide attendees through a high-level tour of the knowledge-infused learning methods, basic familiarity into open-domain autonomous driving datasets/challenges, and the process of solving domain problems using neuro-symbolic AI methods. We'll be covering the following modules in this tutorial.\n </p>\n <ul>\n  <li><b>Knowledge-infused Learning (KL): </b>  KL a form of neuro-symbolic AI is a novel paradigm that seeks to incorporate a variety of explicit (symbolic) knowledge into a data-driven statistical AI framework that supports advancement in machine intelligence. Utilizing knowledge and data in deep learning models to enable learning from lower-level syntactic and lexical features from data through statistical (deep) learning as well as higher-level concepts from knowledge. Using knowledge also allows greater transparency in the decision-making, and enables explanations that users need for informed decision making. Recently, researchers have categorized the recent approaches into a continuum that comprises of three stages; namely, shallow, semi-deep, and deep infusion. We will provide a detailed overview for each stage of knowledge infusion with examples across several application domains. (<i>See relevant resources:</i> [1])</li><br>\n\n  <li><b>Applications for Autonomous Driving: </b>  Despite recent advancements, AD is still far from ready to meet full level-5 autonomy requirements. The primary obstacle is the <i>open-world</i> environment in which the autonomous vehicle must operate. Navigating this environment requires making informed decisions and taking actions within novel and complex situations. While machine learning, in general, and autonomous driving, in particular, have had much success in <i>closed-world</i> environments with lots of experiential training data, the challenges posed by an open-world environment are yet to be resolved. Additionally, the full autonomy of self-driving and its widespread usage poses a new set of non-technical challenges, including user acceptance, accountability, explainability, and conformance to legal, ethical, and societal boundaries. We believe that knowledge-infused learning -- through an integration of domain knowledge and machine learning -- is a potent tool to overcome such challenges. (<i>See relevant resources:</i> [3])</li><br>\n   \n  <li><b>Knowledge-based Entity Prediction (KEP) for Improved Machine Perception: </b> <img src=\"../assets/kep.png\" align=\"right\" width=\"330\" height=\"200\" /> Machine perception is one of the key technical problems in AD where detecting and recognizing objects/events in a scene (i.e. environmental perception) is a critical task. This, however, is particularly challenging as there are several reasons why an entity could go unrecognized. This includes, but not limited to, sensor failure, occlusion, low resolution (e.g., from weather), or errors in computer vision models. For example, consider the case where an ego vehicle driving through a residential neighborhood and detects only a ball on the road (partial observation) and could contain unrecognized entities such as <i>Child</i> in the scene.  Knowledge-based entity prediction (KEP) is a novel task that aims to address this issue by leveraging relational knowledge from heterogeneous sources in predicting potentially unrecognized entities. We will show how an innovative knowledge-infused learning approach can be developed for KEP and demonstrate its usefulness considering two high-quality, large-scale real AD datasets. (<i>See relevant resources:</i> [4,5])</li><br>\n\n  <li><b>Leveraging Commonsense for Explainable Scene Clustering: </b>  The task of scene clustering refers to clustering a given set of scenes and assigning descriptive label(s) to each cluster. For example, a cluster may be described as <i>accident</i> scenes with a crashed vehicle, a police car, and an ambulance. Using scenes represented in a knowledge graph, and enriched with commonsense knowledge, it may be possible to automatically generate explanations for semantic clusters. In this tutorial, we will demonstrate how an innovative approach can be developed for explainable scene clustering along with the process of leveraging relevant commonsense knowledge for this task. (<i>See relevant resources:</i> [6])</li><br>\n\n  <li><b>Learning Visual Models for Road Sign Recognition using a Knowledge Graph as a Trainer: </b>  <img src=\"../assets/road_signs.png\" align=\"right\" width=\"370\" height=\"150\" /> The task of recognizing and understanding road signs is an important feature of autonomous driving. Current technology for road sign recognition (RSR) is mainly based on computer vision (CV) algorithms that solely depend on image data distribution of the training domain. Such models, however, tend to fail when applied to a target domain (e.g., road signs from China) that differs from their source domain (e.g. road signs from Germany). Knowledge graph neural network (KG-NN) is a novel neuro-symbolic approach to address the problem of transfer learning by using image-data-invariant auxiliary knowledge. We will show how this technology can be applied to enable transfer learning for the RSR task. (<i>See relevant resources:</i> [7])</li>\n </ul>\n    </v-row>   \n\n    <v-row no-gutters \n      class=\"pt-8\"\n      align=\"center\"\n      justify=\"center\"\n      about id=\"speakers_id\">\n      <h1 class=\"text-h4 font-weight-thin mb-4\">\n              Speakers\n      </h1>\n    </v-row>\n    <v-row \n      class=\"pb-8\"\n      align=\"center\"\n      justify=\"center\"\n      no-gutters>\n      <template v-for=\"(author, idx) in authors\">\n        <biography-card :person=\"author\" :key=\"idx\"/>\n      </template>\n    </v-row>\n    <v-row no-gutters \n      class=\"pt-8\"\n      align=\"center\"\n      justify=\"center\"\n      about id=\"tutorial_program_id\">\n      <h1 class=\"text-h4 font-weight-thin mb-4\">\n              Tutorial Program\n      </h1>\n    </v-row>\n    <v-row \n      class=\"pb-8 pr-8 pl-8\"\n      align=\"center\"\n      justify=\"center\"\n      no-gutters>\n      <v-timeline>\n        <v-timeline-item\n          v-for=\"(item, i) in programItems\"\n          :key=\"i\"\n          :color=\"item.color\"\n          small\n        >\n          <template v-slot:opposite>\n            <span\n              :class=\"`headline font-weight-bold ${item.color}--text`\"\n              v-text=\"item.time\"\n            ></span>\n          </template>\n          <div class=\"py-4\">\n            <h2 :class=\"`headline font-weight-light mb-4 ${item.color}--text`\">\n              {{item.title}}\n            </h2>\n            <div>\n              {{item.description}}\n            </div>\n          </div>\n        </v-timeline-item>\n      </v-timeline>\n    </v-row>\n \n  <v-row no-gutters \n      class=\"pt-8\"\n      align=\"center\"\n      justify=\"center\"\n      about id=\"references_id\">\n      <h1 class=\"text-h4 font-weight-thin mb-4\">\n              References\n      </h1>\n    </v-row>\n<v-row no-gutters\n      class=\"pa-8\"\n      align=\"center\"\n      justify=\"center\">\n      <p class=\"text-justify\">\n      <ol>\n        <li> Sheth, A., Gaur, M., Kursuncu, U., Wickramarachchi, R.: Shades of knowledge- infused learning for enhancing deep learning. IEEE Internet Computing (2019)</li>\n        <li>Garcez, A.d., Lamb, L.C.: Neurosymbolic ai: The 3rd wave. arXiv preprint arXiv:2012.05876 (2020)</li>\n        <li>Henson, C., Wickramarachchi, R.: <a href=\"https://www.bosch.com/stories/knowledge-infused-learning-for-autonomous-driving/\" target=\"_blank\"> Introduction to knowledge-infused learning for autonomous driving </a> (June 2021)</li>\n        <li> Wickramarachchi, R., Henson, C., Sheth, A.: Knowledge-infused Learning for Entity Prediction in Driving Scenes. Frontiers in Big Data 4, 759110 (2021)</li>\n        <li> Wickramarachchi, R., Henson, C., Sheth, A. Knowledge-based Entity Prediction for Improved Machine Perception in Autonomous Systems. arXiv preprint arXiv:2203.16616 (2022) </li>\n        <li>Chowdhury, S.N., Wickramarachchi, R., Gad-Elrab, M.H., Stepanova, D., Henson, C.: Towards leveraging commonsense knowledge for autonomous driving. In: ISWC (2021)</li>\n        <li> Monka, S., Halilaj, L., Schmid, S., Rettinger, A.: Learning visual models using a knowledge graph as a trainer. In: ISWC (2021)</li>\n  \n</ol>  \n  </p>\n    </v-row>\n\n <v-row no-gutters\n      class=\"pa-8\"\n      align=\"center\"\n      justify=\"center\"> \n\n</v-row>\n  </v-container>\n</template>\n\n<script>\nimport BiographyCard from './BiographyCard.vue'\n\n  export default {\n  components: { \n    BiographyCard\n    },\n    name: 'LandingPage',\n\n    data: () => ({\n      authors: [\n        {\n          name: 'Ruwan Wickramarachchi', \n          imagePath: 'Ruwan.jpeg',\n          company: 'AI Institute - University of South Carolina', \n          logo_path: '', \n          biography: 'Ruwan Wickramarachchi is a Ph.D. student at the AI Institute, University of South Carolina. His dissertation research focuses on introducing expressive knowledge representation and knowledge-infused learning techniques to improve machine perception and context understanding in autonomous systems. He has co-organized several tutorials on Neurosymbolic-AI, particularly at U.S. Semantic Technologies Symposium (US2TS), and ACM Hypertext (HT). Contact him at: ruwan@email.sc.edu'\n        },\n        {\n          name: 'Cory Henson', \n          imagePath: 'Cory.jpeg',\n          company: 'Bosch Research', \n          logo_path: '', \n          biography: 'Cory Henson is a lead research scientist at the Bosch Research and Technology Center in Pittsburgh, PA. His research focuses on the application of knowledge representation and neuro-symbolic AI to enable autonomous driving. He also holds an Adjunct Faculty position at Wright State University. Cory has organized several workshops at ISWC on the topic of Semantic Sensor Networks. Contact him at: cory.henson@us.bosch.com'\n        },\n        {\n          name: 'Sebastian Monka', \n          imagePath: 'Sebastian2.jpg',\n          company: 'Bosch Research and Trier University', \n          logo_path: '', \n          biography: 'Sebastian Monka is a research scientist at Bosch Research in Renningen, Germany, and a Ph.D. candidate at Trier University. His dissertation research focuses on using neuro-symbolic AI and graph neural networks for transfer learning; i.e. the ability to apply ML models to different but related problems. Specifically, this technology has been applied to improving perception systems for autonomous driving. Contact him at: sebastian.monka@de.bosch.com'\n        },\n        {\n          name: 'Daria Stepanova', \n          imagePath: 'Daria.jpeg',\n          company: 'Bosch Center for Artificial Intelligence', \n          logo_path: '', \n          biography: 'Daria Stepanova is a research scientist at Bosch Center for Artificial Intelligence, Renningen, Germany. Her research interests include neuro-symbolic AI, logic programming, as well as reasoning over knowledge graphs. Previously Daria was a senior researcher at Max Plank Institute for Informatics (Germany), where she was heading a group on Semantic Data. She has delivered several talks at international events in the Semantic Web domain and has served as session chair for ESWC. Contact her at: daria.stepanova@de.bosch.com'\n        },\n        {\n          name: 'Amit Sheth', \n          imagePath: 'Amit2.jpeg',\n          company: 'AI Institute - University of South Carolina', \n          logo_path: '', \n          biography: 'Amit Sheth is the founding director of the AI Institute, University of South Carolina (AIISC). His current core research includes knowledge-infused learning and explanationability. He is a fellow of IEEE, AAAI, AAAS, and ACM. He has co-organized >100 international events and tutorials, and is among the top 50 computer scientists in the USA. He has founded three companies by licensing his university research outcomes, including the first Semantic Web company in 1999 that pioneered technology similar to what is found today in Google Semantic Search and KG. Contact him at: amit@sc.edu'\n        }\n      ],\n      programItems: [\n        {\n          color: 'red',\n          //time: 'Time: TBD',\n          title: 'Introduction to Knowledge-infused Learning',\n          description: ''\n        },\n        {\n          color: 'purple',\n          //time: 'Time: TBD',\n          title: 'Applications for Autonomous Driving',\n          description: ''\n        },\n        {\n          color: 'green',\n          //time: 'Time: TBD',\n          title: 'Knowledge-based Entity Prediction (KEP) ',\n          description: ''\n        },\n        {\n          color: 'orange',\n          //time: 'Time: TBD',\n          title: 'Commonsense for Explainable Scene Clustering ',\n          description: ''\n        },\n        {\n          color: 'blue',\n          //time: 'Time: TBD',\n          title: 'Road Sign Recognition using a KG as a Trainer',\n          description: ''\n        },\n      ],\n    }),\n  }\n</script>\n\n\n<style lang=\"scss\">\n\n  .full-width{\n    width: 100%; \n  }\n  .start-image{\n    width: 100%;\n    padding: 0px}\n\n  .heading-text{ \n      color: white;\n      //-webkit-text-stroke: 0.5px #4B296B;\n    }\n\n  h4, h5 {\n       margin: 100;\n    }\n\n</style>","import mod from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40[0].rules[0].use[1]!../../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./LandingPage.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js??clonedRuleSet-40[0].rules[0].use[1]!../../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./LandingPage.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./LandingPage.vue?vue&type=template&id=0e836efa&\"\nimport script from \"./LandingPage.vue?vue&type=script&lang=js&\"\nexport * from \"./LandingPage.vue?vue&type=script&lang=js&\"\nimport style0 from \"./LandingPage.vue?vue&type=style&index=0&lang=scss&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports\n\n/* vuetify-loader */\nimport installComponents from \"!../../node_modules/vuetify-loader/lib/runtime/installComponents.js\"\nimport { VCol } from 'vuetify/lib/components/VGrid';\nimport { VContainer } from 'vuetify/lib/components/VGrid';\nimport { VParallax } from 'vuetify/lib/components/VParallax';\nimport { VRow } from 'vuetify/lib/components/VGrid';\nimport { VTimeline } from 'vuetify/lib/components/VTimeline';\nimport { VTimelineItem } from 'vuetify/lib/components/VTimeline';\ninstallComponents(component, {VCol,VContainer,VParallax,VRow,VTimeline,VTimelineItem})\n","<template>\n  <v-app>\n    <v-app-bar\n        app\n        fixed\n        height=\"8\"\n        dark\n        color=\"#4b296b\"\n        >\n        <template v-slot:img=\"{ props }\">\n            <v-img\n              v-bind=\"props\"\n            ></v-img>\n        </template>\n        <template v-slot:extension>\n          <v-tabs\n            >\n            <v-app-bar-nav-icon\n            @click=\"$vuetify.goTo('#main_id')\"\n              >\n            </v-app-bar-nav-icon>\n            <v-tab\n            @click=\"$vuetify.goTo('#abstract_id')\"\n              >\n              Abstract</v-tab>\n            <v-tab\n            @click=\"$vuetify.goTo('#motivation_id')\"\n              >\n              Motivation</v-tab>\n            <v-tab\n            @click=\"$vuetify.goTo('#detailed_description_id')\"\n              >\n              Detailed Description</v-tab>\n            <v-tab\n              @click=\"$vuetify.goTo('#speakers_id')\"\n              >\n              Speakers</v-tab>\n            <v-tab\n            @click=\"$vuetify.goTo('#tutorial_program_id')\"\n              >\n              Tutorial Program</v-tab>\n            <v-tab\n            @click=\"$vuetify.goTo('#references_id')\"\n              >\n              References</v-tab>\n          </v-tabs>\n        </template>\n    </v-app-bar>\n    <v-main>\n      <LandingPage/>\n    </v-main>\n  </v-app>\n</template>\n\n<script>\nimport LandingPage from './components/LandingPage';\n\nexport default {\n  name: 'App',\n\n  components: {\n    LandingPage,\n  },\n\n  data: () => ({\n    //\n  }),\n};\n</script>\n","import mod from \"-!../node_modules/thread-loader/dist/cjs.js!../node_modules/babel-loader/lib/index.js??clonedRuleSet-40[0].rules[0].use[1]!../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./App.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../node_modules/thread-loader/dist/cjs.js!../node_modules/babel-loader/lib/index.js??clonedRuleSet-40[0].rules[0].use[1]!../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./App.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./App.vue?vue&type=template&id=6616a3d0&\"\nimport script from \"./App.vue?vue&type=script&lang=js&\"\nexport * from \"./App.vue?vue&type=script&lang=js&\"\n\n\n/* normalize component */\nimport normalizer from \"!../node_modules/@vue/cli-service/node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports\n\n/* vuetify-loader */\nimport installComponents from \"!../node_modules/vuetify-loader/lib/runtime/installComponents.js\"\nimport { VApp } from 'vuetify/lib/components/VApp';\nimport { VAppBar } from 'vuetify/lib/components/VAppBar';\nimport { VAppBarNavIcon } from 'vuetify/lib/components/VAppBar';\nimport { VImg } from 'vuetify/lib/components/VImg';\nimport { VMain } from 'vuetify/lib/components/VMain';\nimport { VTab } from 'vuetify/lib/components/VTabs';\nimport { VTabs } from 'vuetify/lib/components/VTabs';\ninstallComponents(component, {VApp,VAppBar,VAppBarNavIcon,VImg,VMain,VTab,VTabs})\n","import Vue from 'vue';\nimport Vuetify from 'vuetify/lib/framework';\n\nVue.use(Vuetify);\n\nexport default new Vuetify({\n});\n","import Vue from 'vue'\nimport App from './App.vue'\nimport vuetify from './plugins/vuetify'\n\nVue.config.productionTip = false\n\nnew Vue({\n  vuetify,\n  render: h => h(App)\n}).$mount('#app')\n","var map = {\n\t\"./Amit.jpeg\": 4984,\n\t\"./Amit2.jpeg\": 7789,\n\t\"./Cory copy.jpeg\": 2723,\n\t\"./Cory.jpeg\": 2208,\n\t\"./Daria.jpeg\": 2271,\n\t\"./Ruwan.jpeg\": 6516,\n\t\"./Sebastian.jpg\": 5119,\n\t\"./Sebastian2.jpg\": 4397,\n\t\"./Title.png\": 8467,\n\t\"./iswc-logo-light2.png\": 3953,\n\t\"./kep.png\": 443,\n\t\"./logo.png\": 6949,\n\t\"./logo.svg\": 9574,\n\t\"./road_signs.png\": 8664\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = 7173;","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","var deferred = [];\n__webpack_require__.O = function(result, chunkIds, fn, priority) {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar chunkIds = deferred[i][0];\n\t\tvar fn = deferred[i][1];\n\t\tvar priority = deferred[i][2];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every(function(key) { return __webpack_require__.O[key](chunkIds[j]); })) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {\n\tvar getter = module && module.__esModule ?\n\t\tfunction() { return module['default']; } :\n\t\tfunction() { return module; };\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.p = \"/2022/\";","// no baseURI\n\n// object to store loaded and loading chunks\n// undefined = chunk not loaded, null = chunk preloaded/prefetched\n// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded\nvar installedChunks = {\n\t143: 0\n};\n\n// no chunk on demand loading\n\n// no prefetching\n\n// no preloaded\n\n// no HMR\n\n// no HMR manifest\n\n__webpack_require__.O.j = function(chunkId) { return installedChunks[chunkId] === 0; };\n\n// install a JSONP callback for chunk loading\nvar webpackJsonpCallback = function(parentChunkLoadingFunction, data) {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\t// add \"moreModules\" to the modules object,\n\t// then flag all \"chunkIds\" as loaded and fire callback\n\tvar moduleId, chunkId, i = 0;\n\tif(chunkIds.some(function(id) { return installedChunks[id] !== 0; })) {\n\t\tfor(moduleId in moreModules) {\n\t\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t\t}\n\t\t}\n\t\tif(runtime) var result = runtime(__webpack_require__);\n\t}\n\tif(parentChunkLoadingFunction) parentChunkLoadingFunction(data);\n\tfor(;i < chunkIds.length; i++) {\n\t\tchunkId = chunkIds[i];\n\t\tif(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {\n\t\t\tinstalledChunks[chunkId][0]();\n\t\t}\n\t\tinstalledChunks[chunkId] = 0;\n\t}\n\treturn __webpack_require__.O(result);\n}\n\nvar chunkLoadingGlobal = self[\"webpackChunkkl4ad\"] = self[\"webpackChunkkl4ad\"] || [];\nchunkLoadingGlobal.forEach(webpackJsonpCallback.bind(null, 0));\nchunkLoadingGlobal.push = webpackJsonpCallback.bind(null, chunkLoadingGlobal.push.bind(chunkLoadingGlobal));","// startup\n// Load entry module and return exports\n// This entry module depends on other loaded chunks and execution need to be delayed\nvar __webpack_exports__ = __webpack_require__.O(undefined, [998], function() { return __webpack_require__(8963); })\n__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n"],"names":["render","_vm","this","_h","$createElement","_c","_self","attrs","scopedSlots","_u","key","fn","ref","props","_b","on","$event","$vuetify","goTo","_v","proxy","staticRenderFns","staticClass","staticStyle","_l","author","idx","item","i","color","class","domProps","_s","time","title","description","imagePath","person","name","company","show","directives","rawName","value","expression","biography","randomInt","computed","methods","component","VBtn","components","BiographyCard","data","authors","logo_path","programItems","VCol","LandingPage","VApp","Vue","Vuetify","vuetify","h","App","$mount","map","webpackContext","req","id","webpackContextResolve","__webpack_require__","o","e","Error","code","keys","Object","resolve","module","exports","__webpack_module_cache__","moduleId","cachedModule","undefined","__webpack_modules__","m","deferred","O","result","chunkIds","priority","notFulfilled","Infinity","length","fulfilled","j","every","splice","r","n","getter","__esModule","d","a","definition","defineProperty","enumerable","get","g","globalThis","Function","window","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","p","installedChunks","chunkId","webpackJsonpCallback","parentChunkLoadingFunction","moreModules","runtime","some","chunkLoadingGlobal","self","forEach","bind","push","__webpack_exports__"],"sourceRoot":""}